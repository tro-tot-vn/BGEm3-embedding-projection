================================================================================
ğŸ” DATASET QUALITY REPORT - BGE-M3 Embedding Projection
================================================================================

ğŸ“… Date: 2025-10-25
ğŸ“Š Status: âœ… ALL ISSUES FIXED

================================================================================
ğŸš¨ ISSUES FOUND
================================================================================

Issue #1: Duplicate Types in Hard Negatives
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Found:    679 cases (3.3% of hard negatives)
Example:  ["amenity", "amenity"] â†’ ["amenity"]
Impact:   Weight calculation incorrect â†’ training bias
Fix:      scripts/fix_duplicate_types.py
Status:   âœ… FIXED

Issue #2: Location Mismatches (CRITICAL)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Found:    363 cases (5.26% of examples)
Example:  Query: "TÃ¬m trá» Thá»§ Äá»©c"
          Pos:   "PhÃ²ng trá» Quáº­n 10" âŒ WRONG!
Impact:   Model learns WRONG location associations
          â†’ Retrieval returns wrong areas
          â†’ BAD user experience
Fix:      scripts/validate_dataset.py --fix
Status:   âœ… FIXED

================================================================================
ğŸ“Š BEFORE vs AFTER
================================================================================

                          BEFORE        AFTER       CHANGE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total examples:           6,901         6,538       -363 (-5.26%)
Duplicate types:          679           0           âœ… Fixed
Location mismatches:      363           0           âœ… Fixed
Zero weights:             679           0           âœ… Fixed
Invalid entries:          1,042         0           âœ… All cleaned

Dataset Quality:          âš ï¸ Low        âœ… High     âœ¨ Ready!

================================================================================
âœ… FINAL DATASET (CLEANED)
================================================================================

Total examples:              6,538
Total hard negatives:        19,319
Avg hard negatives/example:  2.95

Weight Distribution:
  Range:   1.00 - 3.85
  Mean:    2.06
  Median:  2.30

Top Type Combinations:
  1. ['location']           4,429 (22.9%)
  2. ['amenity']            3,388 (17.5%)
  3. ['amenity', 'area']    2,976 (15.4%)
  4. ['amenity', 'price']   2,586 (13.4%)
  5. ['price']              1,807 (9.4%)

Validation Status:
  âœ… No duplicate types
  âœ… All locations match
  âœ… All weights valid
  âœ… Data structure correct

================================================================================
ğŸ’¾ BACKUPS
================================================================================

All originals safely backed up:
  âœ… data/gen-data-set.json.backup          (before duplicate fix)
  âœ… data/gen-data-set.json.bak             (before weight recalc)
  âœ… data/gen-data-set.json.invalid_backup  (before location fix)

To restore: cp data/gen-data-set.json.backup data/gen-data-set.json

================================================================================
ğŸš€ READY FOR TRAINING
================================================================================

Dataset is now CLEAN and VALIDATED!

Run training:
  python train_script.py --epochs 15

Expected improvements:
  âœ… More stable training
  âœ… Better location understanding
  âœ… Higher retrieval accuracy
  âœ… Better metrics (MRR, Recall@K)

================================================================================
