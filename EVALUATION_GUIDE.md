# ğŸ“Š Evaluation Guide - ÄÃ¡nh GiÃ¡ Model

## ğŸ¯ Overview

File `evaluate_model.py` giÃºp báº¡n Ä‘Ã¡nh giÃ¡ model sau khi train xong.

**Metrics Ä‘Æ°á»£c tÃ­nh:**
- **MRR (Mean Reciprocal Rank):** Vá»‹ trÃ­ trung bÃ¬nh cá»§a káº¿t quáº£ Ä‘Ãºng
- **Recall@K:** % queries tÃ¬m tháº¥y Ä‘Ãºng trong top-K
- **Example Predictions:** Xem cá»¥ thá»ƒ model predict nhÆ° tháº¿ nÃ o

---

## ğŸš€ Quick Start

### **CÃ¡ch 1: Default (ÄÆ¡n giáº£n nháº¥t)**

```bash
python evaluate_model.py
```

**Sáº½:**
- Load model tá»« `checkpoints/bgem3_projection_best.pt`
- Test trÃªn 10% cuá»‘i cá»§a `data/gen-data-set.json`
- Show 5 examples

---

### **CÃ¡ch 2: Custom Settings**

```bash
# Evaluate specific checkpoint
python evaluate_model.py --checkpoint checkpoints/bgem3_projection_epoch10.pt

# Use different test data
python evaluate_model.py --data data/test-set.json

# Show more examples
python evaluate_model.py --examples 10

# Faster evaluation (smaller batch)
python evaluate_model.py --batch-size 16

# CPU only
python evaluate_model.py --device cpu

# Use 20% of data as test set
python evaluate_model.py --test-split 0.2

# No examples, just metrics
python evaluate_model.py --no-examples
```

---

## ğŸ“Š Expected Output

```
============================================================
ğŸ¯ BGE-M3 MODEL EVALUATION
============================================================
Device: cuda
ğŸ“¦ Loading model from: checkpoints/bgem3_projection_best.pt
   Epoch: 10
   Loss: 0.4567
âœ… Model loaded successfully

ğŸ“‚ Loading data from: data/gen-data-set.json
âœ… Using last 10% of data: 100 test examples

ğŸ“Š Evaluating on 100 examples...
ğŸ”„ Encoding queries...
Queries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00]
ğŸ”„ Encoding documents...
Documents: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00:00]
ğŸ”„ Computing similarities...
ğŸ”„ Computing metrics...

============================================================
ğŸ“Š EVALUATION RESULTS
============================================================
MRR         :  78.45% â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚
Recall@1    :  65.30% â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚
Recall@5    :  89.20% â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â”‚
Recall@10   :  94.50% â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â”‚
Recall@50   :  99.10% â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚
============================================================

ğŸ’¡ Interpretation:
   ğŸŸ¢ Excellent! Model retrieves correct docs very accurately.
   
   In top-10 results: 94.5% queries find correct match

============================================================
ğŸ” EXAMPLE PREDICTIONS
============================================================

ğŸ“ Example 1:
   Query: phÃ²ng trá» q10 wc riÃªng 25m2 5tr5...

   Similarities:
   âœ… Positive:    0.8523 - Cho thuÃª phÃ²ng Quáº­n 10, 25mÂ², WC khÃ©p kÃ­n, giÃ¡ 5.5...
   âŒ Negative 1:  0.7234 - Cho thuÃª phÃ²ng Quáº­n 11, 25mÂ², WC khÃ©p kÃ­n, giÃ¡ 5.5...
   âŒ Negative 2:  0.6891 - Cho thuÃª phÃ²ng Quáº­n 10, 30mÂ², WC khÃ©p kÃ­n, giÃ¡ 6...
   âŒ Negative 3:  0.6512 - Cho thuÃª phÃ²ng Quáº­n 10, 25mÂ², WC chung, giÃ¡ 5.5...
   âœ… Correct! Positive has highest similarity
   ğŸ“Š Margin: +0.1289 (higher is better)

...

============================================================
âœ… Evaluation complete!
============================================================
```

---

## ğŸ“ˆ Hiá»ƒu Metrics

### **MRR (Mean Reciprocal Rank)**

**Ã nghÄ©a:** Trung bÃ¬nh nghá»‹ch Ä‘áº£o vá»‹ trÃ­ cá»§a káº¿t quáº£ Ä‘Ãºng

**CÃ´ng thá»©c:** `MRR = average(1 / rank_of_correct_doc)`

**VÃ­ dá»¥:**
- Query 1: Káº¿t quáº£ Ä‘Ãºng á»Ÿ vá»‹ trÃ­ #1 â†’ RR = 1.0
- Query 2: Káº¿t quáº£ Ä‘Ãºng á»Ÿ vá»‹ trÃ­ #2 â†’ RR = 0.5
- Query 3: Káº¿t quáº£ Ä‘Ãºng á»Ÿ vá»‹ trÃ­ #5 â†’ RR = 0.2
- **MRR = (1.0 + 0.5 + 0.2) / 3 = 0.567**

**Threshold:**
- **> 0.8:** ğŸŸ¢ Excellent
- **0.6 - 0.8:** ğŸŸ¡ Good
- **0.4 - 0.6:** ğŸŸ  Fair
- **< 0.4:** ğŸ”´ Poor

---

### **Recall@K**

**Ã nghÄ©a:** % queries cÃ³ káº¿t quáº£ Ä‘Ãºng trong top-K

**VÃ­ dá»¥:**
- 100 queries total
- 65 queries cÃ³ káº¿t quáº£ Ä‘Ãºng á»Ÿ vá»‹ trÃ­ #1 â†’ **Recall@1 = 65%**
- 89 queries cÃ³ káº¿t quáº£ Ä‘Ãºng trong top-5 â†’ **Recall@5 = 89%**
- 95 queries cÃ³ káº¿t quáº£ Ä‘Ãºng trong top-10 â†’ **Recall@10 = 95%**

**Threshold (Cho rental search):**
- **Recall@1 > 60%:** Good
- **Recall@5 > 85%:** Good
- **Recall@10 > 90%:** Good
- **Recall@50 > 95%:** Good

---

## ğŸ” Example Predictions Explained

```
ğŸ“ Example 1:
   Query: phÃ²ng trá» q10 wc riÃªng 25m2 5tr5...

   Similarities:
   âœ… Positive:    0.8523  â† HIGHEST = Good! âœ…
   âŒ Negative 1:  0.7234  â† Lower (location wrong)
   âŒ Negative 2:  0.6891  â† Lower (area/price wrong)
   âŒ Negative 3:  0.6512  â† Lowest (amenity wrong)
```

**Good model:**
- âœ… Positive cÃ³ similarity **cao nháº¥t**
- âœ… Margin (positive - best_negative) **> 0.05**
- âœ… Hard negatives cÃ³ order Ä‘Ãºng (location error > area error > amenity error)

**Bad model:**
- âŒ Negative cÃ³ similarity cao hÆ¡n positive
- âŒ Margin quÃ¡ nhá» (< 0.02)
- âŒ Order cá»§a negatives sai

---

## ğŸ¯ Khi NÃ o Cáº§n Re-train?

### **NÃªn Re-train náº¿u:**

1. **MRR < 0.5**
   - Model khÃ´ng há»c tá»‘t
   - Try: Increase epochs, adjust learning rate

2. **Recall@10 < 80%**
   - Model khÃ´ng phÃ¢n biá»‡t Ä‘Æ°á»£c positive/negative
   - Try: Check hard negatives quality, increase batch size

3. **Margin < 0.05 trong examples**
   - Model khÃ´ng confident
   - Try: Train longer, use more hard negatives

4. **Val loss tÄƒng (overfitting)**
   - Model memorize training data
   - Try: More data, stronger regularization

---

## ğŸ“ Compare Multiple Checkpoints

```bash
# Evaluate all checkpoints
for epoch in 2 4 6 8 10; do
    echo "Evaluating epoch $epoch..."
    python evaluate_model.py \
        --checkpoint checkpoints/bgem3_projection_epoch${epoch}.pt \
        --no-examples \
        2>&1 | grep -E "MRR|Recall@10"
done

# Expected output:
# Evaluating epoch 2...
# MRR         :  65.30%
# Recall@10   :  85.20%
# Evaluating epoch 4...
# MRR         :  72.45%
# Recall@10   :  90.10%
# ...
```

---

## ğŸ”¬ Advanced: Create Separate Test Set

**Tá»‘t nháº¥t:** TÃ¡ch test set riÃªng, KHÃ”NG dÃ¹ng trong training

```python
# split_data.py
import json
from sklearn.model_selection import train_test_split

with open('data/gen-data-set.json') as f:
    data = json.load(f)

train, test = train_test_split(data, test_size=0.1, random_state=42)

with open('data/train-set.json', 'w') as f:
    json.dump(train, f, ensure_ascii=False, indent=2)

with open('data/test-set.json', 'w') as f:
    json.dump(test, f, ensure_ascii=False, indent=2)

print(f"Train: {len(train)}, Test: {len(test)}")
```

**Then evaluate:**
```bash
python evaluate_model.py --data data/test-set.json --test-split 1.0
```

---

## ğŸ’¡ Tips

1. **Always evaluate on unseen data**
   - Äá»«ng evaluate trÃªn training data!
   - Use last 10% hoáº·c separate test set

2. **Compare with baseline**
   - Evaluate untrained model (random weights)
   - Good model should be much better than random

3. **Check examples visually**
   - Numbers cÃ³ thá»ƒ misleading
   - Xem examples Ä‘á»ƒ hiá»ƒu model behavior

4. **Track metrics over epochs**
   - Plot MRR/Recall vs epochs
   - Detect overfitting early

---

## ğŸ“š Full Command Reference

```bash
# Basic
python evaluate_model.py

# Custom checkpoint
python evaluate_model.py --checkpoint path/to/model.pt

# Custom data
python evaluate_model.py --data data/test-set.json

# Custom test split (20% of data)
python evaluate_model.py --test-split 0.2

# Device
python evaluate_model.py --device cuda
python evaluate_model.py --device cpu

# Batch size (for memory constraints)
python evaluate_model.py --batch-size 16

# Examples
python evaluate_model.py --examples 10     # Show 10 examples
python evaluate_model.py --examples 0      # No examples
python evaluate_model.py --no-examples     # No examples (flag)

# Combine
python evaluate_model.py \
    --checkpoint checkpoints/bgem3_projection_best.pt \
    --data data/test-set.json \
    --device cuda \
    --batch-size 32 \
    --examples 5
```

---

## â“ Troubleshooting

### **Error: FileNotFoundError**
```
âŒ Checkpoint not found
```
**Fix:** Check checkpoint path
```bash
ls checkpoints/
python evaluate_model.py --checkpoint checkpoints/bgem3_projection_final.pt
```

### **Error: CUDA OOM**
```
RuntimeError: CUDA out of memory
```
**Fix:** Reduce batch size
```bash
python evaluate_model.py --batch-size 16  # or smaller
```

### **Metrics are 0% or very low**
**Possible causes:**
1. Model not trained (using random weights)
2. Wrong checkpoint loaded
3. Data format mismatch

**Fix:** 
```bash
# Check training loss in checkpoint
python -c "
import torch
ckpt = torch.load('checkpoints/bgem3_projection_best.pt')
print('Loss:', ckpt.get('loss', 'N/A'))
print('Epoch:', ckpt.get('epoch', 'N/A'))
"
```

---

**Happy Evaluating! ğŸ“Š**

