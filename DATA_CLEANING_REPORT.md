# ğŸ”§ Data Cleaning Report

## Overview

This report documents all data quality issues found and fixed in the BGE-M3 embedding projection dataset (`gen-data-set.json`).

---

## ğŸš¨ Issues Found & Fixed

### Issue #1: Duplicate Types in Hard Negatives

**Problem:**
- 679 hard negative examples (3.3%) had duplicate types
- Example: `["location", "price", "amenity", "amenity"]`

**Impact:**
- Weight calculation would be incorrect (inflated)
- Model would over-weight certain features
- Training bias towards duplicated features

**Fix:**
- Created `scripts/fix_duplicate_types.py`
- Deduplicated type arrays while preserving order
- Example fix: `["amenity", "amenity"]` â†’ `["amenity"]`

**Result:**
```
âœ… Fixed 679 duplicate entries
âœ… Recalculated all weights correctly
```

**Backup:** `data/gen-data-set.json.backup`

---

### Issue #2: Location Mismatches (CRITICAL)

**Problem:**
- 363 examples (5.26%) had mismatched locations between query and positive
- Example:
  ```
  Query: "TÃ¬m trá» khu Thá»§ Äá»©c diá»‡n tÃ­ch 25m2 giÃ¡ 5.5tr"
  Pos:   "PhÃ²ng trá» 25m2... á»Ÿ Quáº­n 10..."  âŒ WRONG LOCATION!
  ```

**Why This is Critical:**
In contrastive learning, the positive example **MUST** match the query. Location mismatches teach the model:
- `similarity("Thá»§ Äá»©c", "Quáº­n 10")` should be HIGH âŒ **WRONG!**
- This causes the model to confuse different locations
- Location is the most important feature (weight 2.5)
- Retrieval results would return wrong areas â†’ Bad UX

**Types of Mismatches Found:**
1. **Cross-city mismatches:**
   - Query: HÃ  Ná»™i (Cáº§u Giáº¥y, Äá»‘ng Äa) â†’ Pos: TPHCM (Q10, BÃ¬nh Tháº¡nh)
   
2. **Different districts:**
   - Query: Quáº­n 3 â†’ Pos: Quáº­n 10
   
3. **Missing locations:**
   - Query: "phÃ²ng trá» q10..." â†’ Pos: "{pos}" (template not filled)

**Fix:**
- Created `scripts/validate_dataset.py`
- Validates location match between query and positive
- Removes invalid entries (363 examples)
- Normalizes location names (Q10 = Q.10 = Quáº­n 10)

**Result:**
```
âœ… Removed 363 invalid entries (5.26%)
âœ… 0 location mismatches remaining
âœ… Dataset size: 6901 â†’ 6538 examples
```

**Backup:** `data/gen-data-set.json.invalid_backup`

---

## ğŸ“Š Final Dataset Statistics

```
Total examples:              6,538
Total hard negatives:        19,319
Avg hard negatives/example:  2.95

Weight Distribution:
  Min:     1.00 (single feature errors)
  Max:     3.85 (4 feature errors)
  Mean:    2.06
  Median:  2.30
```

### Type Distribution (Top 5)

| Type Combination | Count | Percentage |
|------------------|-------|------------|
| `['location']` | 4,429 | 22.9% |
| `['amenity']` | 3,388 | 17.5% |
| `['amenity', 'area']` | 2,976 | 15.4% |
| `['amenity', 'price']` | 2,586 | 13.4% |
| `['price']` | 1,807 | 9.4% |

---

## ğŸ”§ Tools Created

### 1. `scripts/fix_duplicate_types.py`
```bash
# Remove duplicate types from hard negatives
python scripts/fix_duplicate_types.py

# Options:
python scripts/fix_duplicate_types.py --input data/gen-data-set.json --output data/cleaned.json
python scripts/fix_duplicate_types.py --no-backup
```

**Features:**
- Deduplicates type arrays while preserving order
- Creates automatic backup
- Shows first 5 fixes for verification

### 2. `scripts/validate_dataset.py`
```bash
# Validate dataset (check only)
python scripts/validate_dataset.py

# Validate and fix
python scripts/validate_dataset.py --fix

# Options:
python scripts/validate_dataset.py --input data/gen-data-set.json --fix
python scripts/validate_dataset.py --fix --output data/cleaned.json
python scripts/validate_dataset.py --fix --no-backup
```

**Features:**
- Validates location match between query and positive
- Normalizes location names for comparison
- Removes invalid entries with detailed reporting
- Creates automatic backup

---

## ğŸ”„ Cleaning Workflow

If you need to clean a new dataset, follow this workflow:

```bash
# Step 1: Fix duplicate types
python scripts/fix_duplicate_types.py
# â†’ Removes duplicate types in hard_neg

# Step 2: Validate and fix location mismatches
python scripts/validate_dataset.py --fix
# â†’ Removes entries with location mismatches

# Step 3: Recalculate weights
python scripts/populate_weights.py
# â†’ Updates weights based on fixed types

# Step 4: Final validation
python scripts/validate_dataset.py
# â†’ Verify dataset is clean (should show 0 errors)
```

---

## âœ… Validation Checklist

Before training, verify:

- [x] No duplicate types in hard negatives
- [x] All query-positive pairs have matching locations
- [x] All weights are non-zero and in valid range (1.0 - 3.85)
- [x] No empty type arrays
- [x] All type values are valid (`location`, `price`, `area`, `amenity`, `requirement`)

---

## ğŸ“ Backup Files

All cleaning operations create backups automatically:

```
data/gen-data-set.json.backup          # Before duplicate fix
data/gen-data-set.json.bak             # Before weight recalc
data/gen-data-set.json.invalid_backup  # Before location fix
```

To restore from backup:
```bash
# Restore from any backup
cp data/gen-data-set.json.backup data/gen-data-set.json
```

---

## ğŸ¯ Impact on Training

### Before Cleaning:
- âŒ 679 duplicate types â†’ incorrect weights
- âŒ 363 location mismatches â†’ model learns wrong associations
- âŒ Training would be unstable and inaccurate

### After Cleaning:
- âœ… Correct weights for all hard negatives
- âœ… All query-positive pairs are valid
- âœ… Dataset size reduced by 5.26% but quality improved
- âœ… Ready for high-quality training

**Expected Improvements:**
- Better location understanding
- More stable training (no conflicting signals)
- Higher retrieval accuracy
- Better metrics (MRR, Recall@K)

---

## ğŸ’¡ Recommendations

### For Future Data Generation:

1. **Validate location match** in data generation script
   - Ensure query location matches positive location
   - Use normalized location comparison

2. **Deduplicate types** before saving
   - Use `set()` or check for duplicates in generation

3. **Add validation step** to data pipeline
   - Run `validate_dataset.py` after generation
   - Fix issues before training

4. **Create test set** with known good examples
   - Manually verify a sample of 50-100 examples
   - Use as gold standard for validation

### For Training:

1. **Split train/val AFTER cleaning**
   - Current split: 90% train, 10% val
   - Already handled in `train_script.py`

2. **Monitor training metrics**
   - If training is unstable â†’ check data quality
   - If val loss plateaus early â†’ may need more data

3. **Evaluate on held-out test set**
   - Use `evaluate_model.py` after training
   - Check if location retrieval is accurate

---

## ğŸ“ Contact

If you encounter data quality issues not covered here, document them and add fixes to this workflow.

**Last Updated:** 2025-10-25
**Dataset Version:** v1.1 (cleaned)
**Total Examples:** 6,538
**Quality Score:** âœ… High (all known issues fixed)

