# ğŸ”§ Fix NaN Issue - Clear Cache & Test

## âŒ Váº¥n Ä‘á»

Náº¿u báº¡n tháº¥y `[nan]` khi test model á»Ÿ repo khÃ¡c, cÃ³ thá»ƒ do **HF cache cÅ©** (trÆ°á»›c khi fix bug).

## âœ… Giáº£i phÃ¡p

### 1. Clear Hugging Face Cache

```bash
# XÃ³a cache cá»§a model nÃ y
rm -rf ~/.cache/huggingface/hub/models--lamdx4--bge-m3-vietnamese-rental-projection

# Hoáº·c xÃ³a toÃ n bá»™ cache (náº¿u cáº§n)
# rm -rf ~/.cache/huggingface/hub/*
```

### 2. Test Standalone

Táº¡o file `test.py` á»Ÿ báº¥t ká»³ Ä‘Ã¢u (NGOÃ€I project nÃ y):

```python
#!/usr/bin/env python3
"""Test model tá»« HF Hub (standalone)"""

import torch
from transformers import AutoModel

# Load model
print("Downloading model from HF Hub...")
model = AutoModel.from_pretrained(
    "lamdx4/bge-m3-vietnamese-rental-projection",
    trust_remote_code=True
)

# Test
texts = ["PhÃ²ng trá» Quáº­n 10, 25mÂ², 5tr"]
embeddings = model.encode(texts)

print(f"Shape: {embeddings.shape}")
print(f"Sample: {embeddings[0][:5]}")

# Check NaN
if torch.isnan(embeddings).any():
    print("âŒ ERROR: Found NaN!")
else:
    print("âœ… SUCCESS: No NaN!")
```

Cháº¡y:
```bash
python test.py
```

### 3. Káº¿t quáº£ mong Ä‘á»£i

```
âœ… SUCCESS: No NaN!
Shape: torch.Size([1, 128])
Sample: tensor([-0.0486, -0.1078, -0.0124,  0.1243,  0.0297])
```

---

## ğŸ› Bugs Ä‘Ã£ fix

### Bug 1: Missing `head.` prefix (CRITICAL!)
- **Váº¥n Ä‘á»:** SafeTensors cÃ³ key `linear.weight` thay vÃ¬ `head.linear.weight`
- **Káº¿t quáº£:** Embeddings hoÃ n toÃ n sai (max diff = 0.38)
- **Fix:** Giá»¯ nguyÃªn prefix khi save weights

### Bug 2: Missing tokenizer (CRITICAL!)
- **Váº¥n Ä‘á»:** `encode()` gá»i `self.tokenizer` nhÆ°ng khÃ´ng tá»“n táº¡i
- **Káº¿t quáº£:** NaN values khi test standalone
- **Fix:** Lazy load tokenizer trong property

---

## âœ… Verified

Model Ä‘Ã£ Ä‘Æ°á»£c test:
- âœ… Local test (trong project folder)
- âœ… Standalone test (á»Ÿ /tmp, khÃ´ng cÃ³ local code)
- âœ… So sÃ¡nh vá»›i original model (max diff = 0.0)
- âœ… Similarity ranking chÃ­nh xÃ¡c

---

## ğŸŒ Model Ä‘Ã£ sáºµn sÃ ng

**URL:** https://huggingface.co/lamdx4/bge-m3-vietnamese-rental-projection

**Usage:**
```python
from transformers import AutoModel

model = AutoModel.from_pretrained(
    "lamdx4/bge-m3-vietnamese-rental-projection",
    trust_remote_code=True
)

# Encode texts
embeddings = model.encode(["Your text here"])
```

---

## ğŸ“ Notes

- Model size: ~513 KB (chá»‰ projection head)
- Users váº«n cáº§n load BGE-M3 base (tá»± Ä‘á»™ng download khi khá»Ÿi táº¡o)
- Tokenizer Ä‘Æ°á»£c lazy load (download láº§n Ä‘áº§u tiÃªn gá»i `encode()`)

